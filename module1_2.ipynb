{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e32fd333",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a4b34d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizer import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(\"tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d1a23a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Embeeding yani Sözlük Anlamlarının Sayısal Değerleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "41e94581",
   "metadata": {},
   "outputs": [],
   "source": [
    "the_1 = 0.1 #parlaklık ekseni\n",
    "the_2 = 0.4 #sertlik ekseni\n",
    "the_3 = 0.0 #mavilik ekseni\n",
    "the_4 = 0.0 #kırmızılık ekseni\n",
    "the_5 = 0.7 #yeşillik ekseni\n",
    "\n",
    "capital_1 = 0.0 #parlaklık ekseni\n",
    "capital_2 = 0.2 #sertlik ekseni\n",
    "capital_3 = 0.24 #mavilik ekseni\n",
    "capital_4 = 0.3 #kırmızılık ekseni\n",
    "capital_5 = 0.1 #yeşillik ekseni\n",
    "#Kelimeler 5 boyutlu uzayda incelenir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2cbb17e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.1, 0.0, 0.0, 0.0],\n",
       " [0.4, 0.2, 0.04, 0.3],\n",
       " [0.0, 0.24, 0.02, 0.01],\n",
       " [0.0, 0.0, 0.03, 0.01],\n",
       " [0.0, 0.0, 0.0, 0.0])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dict_v2 = {\n",
    "    \"the\": [0.1, 0.0, 0.0, 0.0],\n",
    "    \"capital\": [0.4, 0.2, 0.04, 0.3],\n",
    "    \"of\": [0.0, 0.24, 0.02, 0.01],\n",
    "    \"united\": [0.0, 0.0, 0.03, 0.01],\n",
    "    \"states\": [0.0, 0.0, 0.0, 0.0]\n",
    "}\n",
    "\n",
    "dict_v2[\"the\"], dict_v2[\"capital\"], dict_v2[\"of\"], dict_v2[\"united\"], dict_v2[\"states\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "31744d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'temp-plot.html'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.offline as pyo\n",
    "\n",
    "data = [\n",
    "    go.Scatter3d(\n",
    "        x=[0.1, 0.4, 0.0, 0.0, 0.0],\n",
    "        y=[0.0, 0.2, 0.24, 0.0, 0.0],\n",
    "        z=[0.0, 0.0, 0.0, 0.03, 0.0],\n",
    "        mode=\"markers+text\",\n",
    "        marker=dict(\n",
    "            size=10,\n",
    "            color=\"red\",\n",
    "        ),\n",
    "        text=[\"the\", \"capital\", \"of\", \"united\", \"states\"],\n",
    "        hoverinfo=\"text\"\n",
    "    )\n",
    "]\n",
    "\n",
    "layout = go.Layout(\n",
    "    scene=dict(\n",
    "        xaxis_title=\"Sertlik\",\n",
    "        yaxis_title=\"Parlaklık\",\n",
    "        zaxis_title=\"Kırmızılık\",\n",
    "    ),\n",
    "    title=\"Sözlük V1\",\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "pyo.plot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "40229c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.offline as pyo\n",
    "\n",
    "def plot_dots(sentences_data, title):\n",
    "    data = [\n",
    "        go.Scatter3d(\n",
    "            x=sentence_data[\"words\"][:, 0],\n",
    "            y=sentence_data[\"words\"][:, 1],\n",
    "            z=sentence_data[\"words\"][:, 2],\n",
    "            marker=dict(\n",
    "                size=10,\n",
    "                color=sentence_data[\"color\"],\n",
    "            ),\n",
    "            text=sentence_data[\"labels\"],\n",
    "            hoverinfo=\"text\",\n",
    "        )   for sentence_data in sentences_data\n",
    "    ]\n",
    "\n",
    "\n",
    "    layout = go.Layout(\n",
    "    scene=dict(\n",
    "        xaxis_title=\"Sertlik\",\n",
    "        yaxis_title=\"Parlaklık\",\n",
    "        zaxis_title=\"Kırmızılık\",\n",
    "        ),\n",
    "        title=title,\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    pyo.plot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "deb485b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "sentences = [\n",
    "    {\n",
    "        \"words\": np.array([\n",
    "        [0.1, 0.0, 0.0, 0.0],\n",
    "        [0.4, 0.2, 0.04, 0.3],\n",
    "        [0.0, 0.24, 0.02, 0.01],\n",
    "        [0.0, 0.0, 0.03, 0.01],\n",
    "        [0.0, 0.0, 0.0, 0.0]\n",
    "        ]),\n",
    "        \"labels\": [\"the\", \"capital\", \"of\", \"united\", \"states\"],\n",
    "        \"color\": \"red\",\n",
    "    }\n",
    "]\n",
    "\n",
    "plot_dots(sentences, \"Sözlük V1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c6312a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "embeddings = torch.nn.Embedding(num_embeddings=64, embedding_dim=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "78cde2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"the capital of united states and the capital of france\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "873a5c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t_/szm46pqj0zv61p2d4vk_p97m0000gn/T/ipykernel_99160/1339664811.py:2: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 61,  1, 61,  2, 61,  3, 61,  4, 58, 61, 10, 61,  0, 61,  1, 61,  2,\n",
       "        61,  8])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.encode(sentence)\n",
    "tokens = torch.tensor(tokens)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "30d2a5f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2560,  0.8956,  0.1675,  0.7514],\n",
       "        [ 0.1643, -0.3161,  0.1285, -0.5277],\n",
       "        [ 2.4142,  1.0206, -0.4405, -1.7342],\n",
       "        [ 0.1643, -0.3161,  0.1285, -0.5277],\n",
       "        [-1.2362,  1.5786, -1.1161,  0.7678],\n",
       "        [ 0.1643, -0.3161,  0.1285, -0.5277],\n",
       "        [-0.5882,  2.1189, -0.5422, -2.4593],\n",
       "        [ 0.1643, -0.3161,  0.1285, -0.5277],\n",
       "        [-1.1108, -1.1187,  0.7580, -0.4957],\n",
       "        [-1.5083, -0.7200, -1.1910,  1.3271],\n",
       "        [ 0.1643, -0.3161,  0.1285, -0.5277],\n",
       "        [ 0.9912, -0.0586,  1.1788,  0.6222],\n",
       "        [ 0.1643, -0.3161,  0.1285, -0.5277],\n",
       "        [-1.2560,  0.8956,  0.1675,  0.7514],\n",
       "        [ 0.1643, -0.3161,  0.1285, -0.5277],\n",
       "        [ 2.4142,  1.0206, -0.4405, -1.7342],\n",
       "        [ 0.1643, -0.3161,  0.1285, -0.5277],\n",
       "        [-1.2362,  1.5786, -1.1161,  0.7678],\n",
       "        [ 0.1643, -0.3161,  0.1285, -0.5277],\n",
       "        [-0.2383, -1.3542,  0.2687,  0.1146]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanings = embeddings(tokens)\n",
    "meanings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5046adaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"the dog chased the cat\"\n",
    "sentence2 = \"the cat chased the dog\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "061b9ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "pos_embeddings = torch.nn.Embedding(num_embeddings=context_length, embedding_dim=4)\n",
    "pos_meanings = pos_embeddings(torch.tensor([i for i in range(context_length)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "87d79a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "\n",
    "def get_position_encoding(context_length, embedding_dim, base=10000, device=\"cpu\"):\n",
    "    p_embeddings = torch.zeros(context_length, embedding_dim, device=device)\n",
    "    for pos in range(context_length):\n",
    "        for i in range(embedding_dim // 2):\n",
    "            p_embeddings[pos, 2 * i] = math.sin(pos / (base ** (2 * i / embedding_dim)))\n",
    "            if i + 1 < embedding_dim:\n",
    "                p_embeddings[pos, 2 * i + 1] = math.cos(pos / (base ** (2 * i + 1 / embedding_dim)))\n",
    "\n",
    "    return p_embeddings.unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a6767401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(1)\n",
    "embeddings = torch.nn.Embedding(num_embeddings=64, embedding_dim=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1283ab51",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanings_in_context = meanings + pos_meanings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "79b56e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    {\n",
    "        \"words\": meanings_in_context.detach().numpy(),\n",
    "        \"labels\": tokenizer.tokenize(sentence),\n",
    "        \"color\": \"red\",\n",
    "    },\n",
    "]\n",
    "plot_dots(sentences, \"Sentence Context Space\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99553371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rotary_position_encoding(input: torch.Tensor, base=10000, device=\"cpu\"):\n",
    "    context_length, dimension = input.shape\n",
    "\n",
    "    assert dimension % 2 == 0, \"dimension must be even \"\n",
    "    half_dimension = dimension // 2\n",
    "\n",
    "    freqs_indices = torch.arange(0, half_dimension, device=device, dtype=torch.float32)\n",
    "\n",
    "    freqs = 1.0 / (base ** (freqs_indices / dimension))\n",
    "\n",
    "    positions = torch.arange(0, context_length, device=device, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "    angles = positions * freqs\n",
    "\n",
    "    sin_angles = torch.sin(angles)\n",
    "    cos_angles = torch.cos(angles)\n",
    "\n",
    "    input_even = input[:, :dimension // 2]\n",
    "    input_odd = input[:, dimension // 2:]\n",
    "\n",
    "    input_even_rotated = input_even * cos_angles - input_odd * sin_angles\n",
    "    input_odd_rotated = input_even * sin_angles + input_odd * cos_angles\n",
    "\n",
    "    input_rotated = torch.empty_like(input)\n",
    "    input_rotated[:, :dimension // 2] = input_even_rotated\n",
    "    input_rotated[:, dimension // 2:] = input_odd_rotated\n",
    "\n",
    "    return input_rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "40b799dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5256, -0.7502, -1.5256, -0.7502],\n",
       "        [ 0.7703, -0.4455,  0.7703, -0.4455],\n",
       "        [ 1.0032,  0.3476,  1.0032,  0.3476],\n",
       "        [ 0.1878,  1.4736,  0.1878,  1.4736],\n",
       "        [ 0.9850, -1.1467,  0.9850, -1.1467],\n",
       "        [-0.3901, -0.1726, -0.3901, -0.1726],\n",
       "        [ 0.4304,  0.6715,  0.4304,  0.6715],\n",
       "        [ 0.5704, -0.3877,  0.5704, -0.3877],\n",
       "        [-0.4295,  0.5046, -0.4295,  0.5046],\n",
       "        [-0.2444,  0.4010, -0.2444,  0.4010],\n",
       "        [ 0.0073,  0.1824,  0.0073,  0.1824],\n",
       "        [ 1.5852,  0.0908,  1.5852,  0.0908],\n",
       "        [-0.7470,  0.6049, -0.7470,  0.6049],\n",
       "        [ 0.2025, -1.8238,  0.2025, -1.8238],\n",
       "        [ 0.2030,  0.7948,  0.2030,  0.7948],\n",
       "        [ 0.9969,  0.6845,  0.9969,  0.6845],\n",
       "        [-0.1472,  1.0350, -0.1472,  1.0350],\n",
       "        [ 1.6668, -0.0093,  1.6668, -0.0093],\n",
       "        [-1.2130,  0.8516, -1.2130,  0.8516],\n",
       "        [-0.5151,  1.1106, -0.5151,  1.1106],\n",
       "        [ 0.3904, -0.7068,  0.3904, -0.7068],\n",
       "        [ 0.6421,  0.3909,  0.6421,  0.3909],\n",
       "        [-0.2638, -0.2966, -0.2638, -0.2966],\n",
       "        [ 0.8050, -1.1707,  0.8050, -1.1707],\n",
       "        [ 1.0200, -0.2604,  1.0200, -0.2604],\n",
       "        [ 1.2502, -0.0135,  1.2502, -0.0135],\n",
       "        [ 0.9427, -0.4398,  0.9427, -0.4398],\n",
       "        [ 2.0278,  1.0449,  2.0278,  1.0449],\n",
       "        [-1.1894,  0.2543, -1.1894,  0.2543],\n",
       "        [ 0.2019, -0.1931,  0.2019, -0.1931],\n",
       "        [ 0.3813, -0.0315,  0.3813, -0.0315],\n",
       "        [-1.7704, -1.8112, -1.7704, -1.8112]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "random_input = torch.randn(context_length, 4)\n",
    "\n",
    "pos_rotary_encodings = get_rotary_position_encoding(random_input)\n",
    "pos_rotary_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "350e9588",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanings_with_pos_encodings = get_rotary_position_encoding(meanings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "46d5f483",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    {\n",
    "        \"words\": meanings_with_pos_encodings.detach().numpy(),\n",
    "        \"labels\": tokenizer.tokenize(sentence),\n",
    "        \"color\": \"red\",\n",
    "    },\n",
    "    {\n",
    "        \"words\": meanings.detach().numpy(),\n",
    "        \"labels\": tokenizer.tokenize(sentence),\n",
    "        \"color\": \"blue\",\n",
    "    },\n",
    "]\n",
    "\n",
    "plot_dots(sentences, \"Sentence Context Space V3 Rotary Encoding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cfc5d39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODEL LAST ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d556a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from usta_model import UstaModel\n",
    "from usta_tokenizer import UstaTokenizer\n",
    "\n",
    "u_tokenizer = UstaTokenizer(\"tokenizer.json\")\n",
    "model = UstaModel(vocab_size=len(u_tokenizer.vocab), embedding_dim=4, context_length=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

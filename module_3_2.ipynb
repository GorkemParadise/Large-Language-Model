{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 61,  1, 61,  2, 61,  0, 61,  3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from usta_model import UstaModel\n",
    "from usta_tokenizer import UstaTokenizer\n",
    "\n",
    "u_tokenizer = UstaTokenizer(\"tokenizer.json\")\n",
    "\n",
    "prompt = \"the capital of the united\"\n",
    "\n",
    "tokens = u_tokenizer.encode(prompt)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 64])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "u_model = UstaModel(vocab_size=len(u_tokenizer.vocab), embedding_dim=12, num_heads=4, context_length=context_length, num_layers=8)\n",
    "\n",
    "out = u_model(tokens)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the capital of the unitedisis,'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = u_model.generate(tokens, 3)\n",
    "u_tokenizer.decode(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4099,\n",
       " 'the capital of the united states is not london. the capital of france is paris, and berlin is the ca')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"text.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "len(text), text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1593, torch.Tensor)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids = u_tokenizer.encode(text)\n",
    "len(token_ids), type(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1593, list)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = token_ids.detach().cpu().numpy().tolist()\n",
    "len(ids), type(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131, 131)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from text_dataset import TextDataset\n",
    "\n",
    "stride = 12\n",
    "\n",
    "dataset = TextDataset(ids, context_length, stride)\n",
    "\n",
    "len(dataset.inputs), len(dataset.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0, 61,  1, 61,  2, 61,  0, 61,  3, 61,  4, 58, 61,  5, 61,  6, 61,  7,\n",
       "         59, 61,  0, 61,  1, 61,  2, 61,  8, 61,  5, 61,  9, 60]),\n",
       " tensor([61,  1, 61,  2, 61,  0, 61,  3, 61,  4, 58, 61,  5, 61,  6, 61,  7, 59,\n",
       "         61,  0, 61,  1, 61,  2, 61,  8, 61,  5, 61,  9, 60, 61]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.inputs[0], dataset.targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11776\n",
      "UstaModel(\n",
      "  (embedding): UstaEmbedding(\n",
      "    (embedding): Embedding(64, 12)\n",
      "  )\n",
      "  (layers): Sequential(\n",
      "    (0): UstaDecoderBlock(\n",
      "      (self_attention): UstaMultiHeadAttention(\n",
      "        (multi_head_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=12, out_features=12, bias=True)\n",
      "        )\n",
      "        (projection): Linear(in_features=12, out_features=12, bias=True)\n",
      "      )\n",
      "      (norm1): UstaLayerNorm()\n",
      "      (mlp): UstaMLP(\n",
      "        (gate_proj): Linear(in_features=12, out_features=12, bias=True)\n",
      "        (up_proj): Linear(in_features=12, out_features=12, bias=True)\n",
      "        (down_proj): Linear(in_features=12, out_features=12, bias=True)\n",
      "        (gelu): GELU()\n",
      "      )\n",
      "      (norm2): UstaLayerNorm()\n",
      "    )\n",
      "    (1): UstaDecoderBlock(\n",
      "      (self_attention): UstaMultiHeadAttention(\n",
      "        (multi_head_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=12, out_features=12, bias=True)\n",
      "        )\n",
      "        (projection): Linear(in_features=12, out_features=12, bias=True)\n",
      "      )\n",
      "      (norm1): UstaLayerNorm()\n",
      "      (mlp): UstaMLP(\n",
      "        (gate_proj): Linear(in_features=12, out_features=12, bias=True)\n",
      "        (up_proj): Linear(in_features=12, out_features=12, bias=True)\n",
      "        (down_proj): Linear(in_features=12, out_features=12, bias=True)\n",
      "        (gelu): GELU()\n",
      "      )\n",
      "      (norm2): UstaLayerNorm()\n",
      "    )\n",
      "    (2): UstaDecoderBlock(\n",
      "      (self_attention): UstaMultiHeadAttention(\n",
      "        (multi_head_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=12, out_features=12, bias=True)\n",
      "        )\n",
      "        (projection): Linear(in_features=12, out_features=12, bias=True)\n",
      "      )\n",
      "      (norm1): UstaLayerNorm()\n",
      "      (mlp): UstaMLP(\n",
      "        (gate_proj): Linear(in_features=12, out_features=12, bias=True)\n",
      "        (up_proj): Linear(in_features=12, out_features=12, bias=True)\n",
      "        (down_proj): Linear(in_features=12, out_features=12, bias=True)\n",
      "        (gelu): GELU()\n",
      "      )\n",
      "      (norm2): UstaLayerNorm()\n",
      "    )\n",
      "    (3): UstaDecoderBlock(\n",
      "      (self_attention): UstaMultiHeadAttention(\n",
      "        (multi_head_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=12, out_features=12, bias=True)\n",
      "        )\n",
      "        (projection): Linear(in_features=12, out_features=12, bias=True)\n",
      "      )\n",
      "      (norm1): UstaLayerNorm()\n",
      "      (mlp): UstaMLP(\n",
      "        (gate_proj): Linear(in_features=12, out_features=12, bias=True)\n",
      "        (up_proj): Linear(in_features=12, out_features=12, bias=True)\n",
      "        (down_proj): Linear(in_features=12, out_features=12, bias=True)\n",
      "        (gelu): GELU()\n",
      "      )\n",
      "      (norm2): UstaLayerNorm()\n",
      "    )\n",
      "    (4): UstaDecoderBlock(\n",
      "      (self_attention): UstaMultiHeadAttention(\n",
      "        (multi_head_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=12, out_features=12, bias=True)\n",
      "        )\n",
      "        (projection): Linear(in_features=12, out_features=12, bias=True)\n",
      "      )\n",
      "      (norm1): UstaLayerNorm()\n",
      "      (mlp): UstaMLP(\n",
      "        (gate_proj): Linear(in_features=12, out_features=12, bias=True)\n",
      "        (up_proj): Linear(in_features=12, out_features=12, bias=True)\n",
      "        (down_proj): Linear(in_features=12, out_features=12, bias=True)\n",
      "        (gelu): GELU()\n",
      "      )\n",
      "      (norm2): UstaLayerNorm()\n",
      "    )\n",
      "    (5): UstaDecoderBlock(\n",
      "      (self_attention): UstaMultiHeadAttention(\n",
      "        (multi_head_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=12, out_features=12, bias=True)\n",
      "        )\n",
      "        (projection): Linear(in_features=12, out_features=12, bias=True)\n",
      "      )\n",
      "      (norm1): UstaLayerNorm()\n",
      "      (mlp): UstaMLP(\n",
      "        (gate_proj): Linear(in_features=12, out_features=12, bias=True)\n",
      "        (up_proj): Linear(in_features=12, out_features=12, bias=True)\n",
      "        (down_proj): Linear(in_features=12, out_features=12, bias=True)\n",
      "        (gelu): GELU()\n",
      "      )\n",
      "      (norm2): UstaLayerNorm()\n",
      "    )\n",
      "    (6): UstaDecoderBlock(\n",
      "      (self_attention): UstaMultiHeadAttention(\n",
      "        (multi_head_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=12, out_features=12, bias=True)\n",
      "        )\n",
      "        (projection): Linear(in_features=12, out_features=12, bias=True)\n",
      "      )\n",
      "      (norm1): UstaLayerNorm()\n",
      "      (mlp): UstaMLP(\n",
      "        (gate_proj): Linear(in_features=12, out_features=12, bias=True)\n",
      "        (up_proj): Linear(in_features=12, out_features=12, bias=True)\n",
      "        (down_proj): Linear(in_features=12, out_features=12, bias=True)\n",
      "        (gelu): GELU()\n",
      "      )\n",
      "      (norm2): UstaLayerNorm()\n",
      "    )\n",
      "    (7): UstaDecoderBlock(\n",
      "      (self_attention): UstaMultiHeadAttention(\n",
      "        (multi_head_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=12, out_features=12, bias=True)\n",
      "        )\n",
      "        (projection): Linear(in_features=12, out_features=12, bias=True)\n",
      "      )\n",
      "      (norm1): UstaLayerNorm()\n",
      "      (mlp): UstaMLP(\n",
      "        (gate_proj): Linear(in_features=12, out_features=12, bias=True)\n",
      "        (up_proj): Linear(in_features=12, out_features=12, bias=True)\n",
      "        (down_proj): Linear(in_features=12, out_features=12, bias=True)\n",
      "        (gelu): GELU()\n",
      "      )\n",
      "      (norm2): UstaLayerNorm()\n",
      "    )\n",
      "  )\n",
      "  (lm_head): Linear(in_features=12, out_features=64, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "parameters_count = sum(p.numel() for p in u_model.parameters())\n",
    "print(parameters_count)\n",
    "\n",
    "print(u_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out0 = u_model(dataset.inputs[0])\n",
    "out0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.4607, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = loss_fn(out0, dataset.targets[0])\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.460687160491943"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(u_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for input, target in dataset:\n",
    "    print(input.shape, target.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 2.754838705062866 average loss: 2.9954407287917975\n",
      "Epoch 2 loss: 2.318660020828247 average loss: 2.4740355124000373\n",
      "Epoch 3 loss: 2.128268003463745 average loss: 2.225120865661679\n",
      "Epoch 4 loss: 2.2206122875213623 average loss: 2.133470241350072\n",
      "Epoch 5 loss: 2.112746238708496 average loss: 2.102477193788718\n",
      "Epoch 6 loss: 2.114819288253784 average loss: 2.082450590970862\n",
      "Epoch 7 loss: 2.1190848350524902 average loss: 2.0791527287650653\n",
      "Epoch 8 loss: 2.1192681789398193 average loss: 2.0736205677949746\n",
      "Epoch 9 loss: 2.108112096786499 average loss: 2.070576813384777\n",
      "Epoch 10 loss: 2.130345106124878 average loss: 2.0749798849338794\n",
      "Epoch 11 loss: 2.1316285133361816 average loss: 2.068679333643149\n",
      "Epoch 12 loss: 2.105117082595825 average loss: 2.05756661091142\n",
      "Epoch 13 loss: 2.103126287460327 average loss: 2.0569195146779067\n",
      "Epoch 14 loss: 2.10575532913208 average loss: 2.0564807207529783\n",
      "Epoch 15 loss: 2.105015277862549 average loss: 2.0558593182163385\n",
      "Epoch 16 loss: 2.1112148761749268 average loss: 2.0519552867831163\n",
      "Epoch 17 loss: 2.099628448486328 average loss: 2.053733315176636\n",
      "Epoch 18 loss: 2.107814073562622 average loss: 2.050870438568465\n",
      "Epoch 19 loss: 2.303403377532959 average loss: 2.060868435233604\n",
      "Epoch 20 loss: 2.0929315090179443 average loss: 2.058329437525218\n",
      "Epoch 21 loss: 2.1065757274627686 average loss: 2.0467372668608452\n",
      "Epoch 22 loss: 2.091233015060425 average loss: 2.0475481684881314\n",
      "Epoch 23 loss: 2.0916831493377686 average loss: 2.042157639983956\n",
      "Epoch 24 loss: 2.102231502532959 average loss: 2.043879646381349\n",
      "Epoch 25 loss: 2.0820021629333496 average loss: 2.0399347898614315\n",
      "Epoch 26 loss: 2.102482318878174 average loss: 2.0351127204094226\n",
      "Epoch 27 loss: 2.102853536605835 average loss: 2.0317714787621535\n",
      "Epoch 28 loss: 2.081632614135742 average loss: 2.0298370705306077\n",
      "Epoch 29 loss: 2.099799156188965 average loss: 2.0262225101922304\n",
      "Epoch 30 loss: 2.0850062370300293 average loss: 2.022858678839589\n",
      "Epoch 31 loss: 2.059492588043213 average loss: 2.020984519528979\n",
      "Epoch 32 loss: 2.07474422454834 average loss: 2.020935316122215\n",
      "Epoch 33 loss: 2.0647780895233154 average loss: 2.016136336872596\n",
      "Epoch 34 loss: 2.0863776206970215 average loss: 2.0276950497663657\n",
      "Epoch 35 loss: 2.0723204612731934 average loss: 2.0239038431007446\n",
      "Epoch 36 loss: 2.072021484375 average loss: 2.0107550575532986\n",
      "Epoch 37 loss: 2.0870678424835205 average loss: 2.0001258686298633\n",
      "Epoch 38 loss: 2.0904948711395264 average loss: 1.9969032156558437\n",
      "Epoch 39 loss: 2.1085662841796875 average loss: 1.9876160903741384\n",
      "Epoch 40 loss: 2.021578311920166 average loss: 1.9739738702774048\n",
      "Epoch 41 loss: 2.1069915294647217 average loss: 1.9617124095217873\n",
      "Epoch 42 loss: 2.071483612060547 average loss: 1.9546130103919341\n",
      "Epoch 43 loss: 2.072584629058838 average loss: 1.9416608874124426\n",
      "Epoch 44 loss: 2.091430187225342 average loss: 1.9259050948019245\n",
      "Epoch 45 loss: 2.060697555541992 average loss: 1.9195359790598163\n",
      "Epoch 46 loss: 2.056558847427368 average loss: 1.917316187429064\n",
      "Epoch 47 loss: 2.076317071914673 average loss: 1.9066901352569348\n",
      "Epoch 48 loss: 2.0273385047912598 average loss: 1.8970699364902408\n",
      "Epoch 49 loss: 1.9718124866485596 average loss: 1.8831470676960835\n",
      "Epoch 50 loss: 1.989830732345581 average loss: 1.8810905017925583\n",
      "Epoch 51 loss: 1.95330810546875 average loss: 1.8886409006045974\n",
      "Epoch 52 loss: 2.060880184173584 average loss: 1.871452137714124\n",
      "Epoch 53 loss: 2.0051748752593994 average loss: 1.859083736215839\n",
      "Epoch 54 loss: 1.9536645412445068 average loss: 1.8976595702062127\n",
      "Epoch 55 loss: 2.1357123851776123 average loss: 1.85878094462038\n",
      "Epoch 56 loss: 1.928624153137207 average loss: 1.8280865199693286\n",
      "Epoch 57 loss: 1.9331302642822266 average loss: 1.8316655650393654\n",
      "Epoch 58 loss: 1.93976628780365 average loss: 1.8199537755878827\n",
      "Epoch 59 loss: 1.9634644985198975 average loss: 1.8211711235628782\n",
      "Epoch 60 loss: 1.9525070190429688 average loss: 1.7902404169999917\n",
      "Epoch 61 loss: 1.870832920074463 average loss: 1.7893268943742942\n",
      "Epoch 62 loss: 1.9344152212142944 average loss: 1.7836742282823752\n",
      "Epoch 63 loss: 2.0775725841522217 average loss: 1.7868173686602644\n",
      "Epoch 64 loss: 2.1828083992004395 average loss: 1.78532713333159\n",
      "Epoch 65 loss: 2.163151741027832 average loss: 1.7790180526616919\n",
      "Epoch 66 loss: 1.972998857498169 average loss: 1.815422186414704\n",
      "Epoch 67 loss: 2.0513389110565186 average loss: 1.7891019883046624\n",
      "Epoch 68 loss: 1.9584194421768188 average loss: 1.7815854513008176\n",
      "Epoch 69 loss: 1.945560097694397 average loss: 1.7569376303039435\n",
      "Epoch 70 loss: 1.8603838682174683 average loss: 1.7419467654847007\n",
      "Epoch 71 loss: 1.9284915924072266 average loss: 1.7427170950037834\n",
      "Epoch 72 loss: 1.7960330247879028 average loss: 1.7527281792109248\n",
      "Epoch 73 loss: 1.8867548704147339 average loss: 1.7414796761884035\n",
      "Epoch 74 loss: 2.114544630050659 average loss: 1.7420122869142138\n",
      "Epoch 75 loss: 1.914933204650879 average loss: 1.7479411645700003\n",
      "Epoch 76 loss: 1.9576318264007568 average loss: 1.7229771013478286\n",
      "Epoch 77 loss: 1.907400131225586 average loss: 1.7239640259560738\n",
      "Epoch 78 loss: 1.8185425996780396 average loss: 1.6911841357937296\n",
      "Epoch 79 loss: 1.857286810874939 average loss: 1.6938230427166887\n",
      "Epoch 80 loss: 1.844301700592041 average loss: 1.7059384038430134\n",
      "Epoch 81 loss: 1.7280133962631226 average loss: 1.738805909193199\n",
      "Epoch 82 loss: 1.7396258115768433 average loss: 1.6963651744463972\n",
      "Epoch 83 loss: 1.7301080226898193 average loss: 1.679766267310572\n",
      "Epoch 84 loss: 1.874941349029541 average loss: 1.6671606602559563\n",
      "Epoch 85 loss: 1.7965410947799683 average loss: 1.66775352536267\n",
      "Epoch 86 loss: 1.7718034982681274 average loss: 1.681487303653746\n",
      "Epoch 87 loss: 1.7492954730987549 average loss: 1.6568085555811876\n",
      "Epoch 88 loss: 1.6484862565994263 average loss: 1.6429733474746004\n",
      "Epoch 89 loss: 1.929284930229187 average loss: 1.656240458706863\n",
      "Epoch 90 loss: 1.6267611980438232 average loss: 1.6356725692749023\n",
      "Epoch 91 loss: 1.7081447839736938 average loss: 1.6474634645549395\n",
      "Epoch 92 loss: 1.632058024406433 average loss: 1.6678703459164568\n",
      "Epoch 93 loss: 1.660220980644226 average loss: 1.6412699213464752\n",
      "Epoch 94 loss: 1.655056357383728 average loss: 1.638494916999613\n",
      "Epoch 95 loss: 1.8574471473693848 average loss: 1.6209218875142455\n",
      "Epoch 96 loss: 1.6018991470336914 average loss: 1.6087236358919217\n",
      "Epoch 97 loss: 1.6393511295318604 average loss: 1.6264059034012657\n",
      "Epoch 98 loss: 1.6949526071548462 average loss: 1.6134893097950302\n",
      "Epoch 99 loss: 1.6204555034637451 average loss: 1.6049262203333032\n",
      "Epoch 100 loss: 1.6070497035980225 average loss: 1.6209922942496438\n"
     ]
    }
   ],
   "source": [
    "epoch = 100\n",
    "\n",
    "for epoch in range(epoch):\n",
    "    total_loss = 0.\n",
    "    for input, target in dataset:\n",
    "        pred = u_model(input)\n",
    "    \n",
    "        loss = loss_fn(pred, target)\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    average_loss = total_loss / len(dataset)\n",
    "    print(f\"Epoch {epoch + 1} loss: {loss.item()} average loss: {average_loss}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1612, grad_fn=<MaxBackward0>),\n",
       " tensor(5),\n",
       " tensor([7.6972e-02, 5.3084e-02, 6.7994e-02, 2.3651e-03, 9.0011e-04, 1.6121e-01,\n",
       "         1.5948e-02, 2.4035e-03, 1.3123e-03, 9.4286e-03, 1.0088e-01, 5.2419e-03,\n",
       "         1.1184e-03, 1.6606e-02, 7.7778e-02, 2.2542e-03, 8.9876e-03, 1.5220e-03,\n",
       "         1.2973e-02, 4.7018e-04, 1.9635e-04, 1.2668e-02, 3.5819e-03, 3.6857e-02,\n",
       "         1.9243e-02, 2.8117e-02, 2.1231e-02, 4.4825e-02, 1.0495e-03, 3.3066e-02,\n",
       "         5.5010e-03, 1.4020e-02, 3.2919e-03, 5.3889e-04, 1.4047e-02, 2.6137e-04,\n",
       "         4.2362e-03, 8.0804e-04, 2.9193e-03, 1.2604e-02, 8.4363e-03, 3.6516e-03,\n",
       "         6.1509e-03, 1.2821e-02, 8.9278e-03, 1.5538e-02, 2.5691e-02, 2.0083e-03,\n",
       "         5.3194e-04, 1.9869e-03, 1.4011e-02, 1.1759e-02, 8.4934e-04, 3.6822e-03,\n",
       "         2.4176e-03, 1.5858e-03, 2.7639e-04, 6.7617e-05, 4.1670e-05, 2.1997e-04,\n",
       "         5.4435e-04, 2.7745e-04, 2.0015e-06, 3.9000e-06],\n",
       "        grad_fn=<SoftmaxBackward0>))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "new_tokens = u_tokenizer.encode(\"madrid is in\")\n",
    "new_tokens = new_tokens.detach().cpu().numpy().tolist()\n",
    "new_tokens.append(61)\n",
    "\n",
    "out = u_model(torch.tensor(new_tokens))\n",
    "\n",
    "probs = torch.softmax(out[-1], dim=-1)\n",
    "max_prob, max_index = torch.max(probs, dim=-1)\n",
    "max_prob, max_index, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save model\n",
    "torch.save(u_model.state_dict(), \"u_model.pth\")\n",
    "\n",
    "# load model\n",
    "u_model.load_state_dict(torch.load(\"u_model.pth\"))\n",
    "\n",
    "# generate text\n",
    "new_tokens = u_tokenizer.encode(\"the capital of the united states is london. the capital of france is\")\n",
    "new_tokens = new_tokens.detach().cpu().numpy().tolist()\n",
    "new_tokens.append(61)\n",
    "len(new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UstaModel(\n",
       "  (embedding): UstaEmbedding(\n",
       "    (embedding): Embedding(64, 12)\n",
       "  )\n",
       "  (layers): Sequential(\n",
       "    (0): UstaDecoderBlock(\n",
       "      (self_attention): UstaMultiHeadAttention(\n",
       "        (multi_head_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (projection): Linear(in_features=12, out_features=12, bias=True)\n",
       "      )\n",
       "      (norm1): UstaLayerNorm()\n",
       "      (mlp): UstaMLP(\n",
       "        (gate_proj): Linear(in_features=12, out_features=12, bias=True)\n",
       "        (up_proj): Linear(in_features=12, out_features=12, bias=True)\n",
       "        (down_proj): Linear(in_features=12, out_features=12, bias=True)\n",
       "        (gelu): GELU()\n",
       "      )\n",
       "      (norm2): UstaLayerNorm()\n",
       "    )\n",
       "    (1): UstaDecoderBlock(\n",
       "      (self_attention): UstaMultiHeadAttention(\n",
       "        (multi_head_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (projection): Linear(in_features=12, out_features=12, bias=True)\n",
       "      )\n",
       "      (norm1): UstaLayerNorm()\n",
       "      (mlp): UstaMLP(\n",
       "        (gate_proj): Linear(in_features=12, out_features=12, bias=True)\n",
       "        (up_proj): Linear(in_features=12, out_features=12, bias=True)\n",
       "        (down_proj): Linear(in_features=12, out_features=12, bias=True)\n",
       "        (gelu): GELU()\n",
       "      )\n",
       "      (norm2): UstaLayerNorm()\n",
       "    )\n",
       "    (2): UstaDecoderBlock(\n",
       "      (self_attention): UstaMultiHeadAttention(\n",
       "        (multi_head_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (projection): Linear(in_features=12, out_features=12, bias=True)\n",
       "      )\n",
       "      (norm1): UstaLayerNorm()\n",
       "      (mlp): UstaMLP(\n",
       "        (gate_proj): Linear(in_features=12, out_features=12, bias=True)\n",
       "        (up_proj): Linear(in_features=12, out_features=12, bias=True)\n",
       "        (down_proj): Linear(in_features=12, out_features=12, bias=True)\n",
       "        (gelu): GELU()\n",
       "      )\n",
       "      (norm2): UstaLayerNorm()\n",
       "    )\n",
       "    (3): UstaDecoderBlock(\n",
       "      (self_attention): UstaMultiHeadAttention(\n",
       "        (multi_head_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (projection): Linear(in_features=12, out_features=12, bias=True)\n",
       "      )\n",
       "      (norm1): UstaLayerNorm()\n",
       "      (mlp): UstaMLP(\n",
       "        (gate_proj): Linear(in_features=12, out_features=12, bias=True)\n",
       "        (up_proj): Linear(in_features=12, out_features=12, bias=True)\n",
       "        (down_proj): Linear(in_features=12, out_features=12, bias=True)\n",
       "        (gelu): GELU()\n",
       "      )\n",
       "      (norm2): UstaLayerNorm()\n",
       "    )\n",
       "    (4): UstaDecoderBlock(\n",
       "      (self_attention): UstaMultiHeadAttention(\n",
       "        (multi_head_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (projection): Linear(in_features=12, out_features=12, bias=True)\n",
       "      )\n",
       "      (norm1): UstaLayerNorm()\n",
       "      (mlp): UstaMLP(\n",
       "        (gate_proj): Linear(in_features=12, out_features=12, bias=True)\n",
       "        (up_proj): Linear(in_features=12, out_features=12, bias=True)\n",
       "        (down_proj): Linear(in_features=12, out_features=12, bias=True)\n",
       "        (gelu): GELU()\n",
       "      )\n",
       "      (norm2): UstaLayerNorm()\n",
       "    )\n",
       "    (5): UstaDecoderBlock(\n",
       "      (self_attention): UstaMultiHeadAttention(\n",
       "        (multi_head_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (projection): Linear(in_features=12, out_features=12, bias=True)\n",
       "      )\n",
       "      (norm1): UstaLayerNorm()\n",
       "      (mlp): UstaMLP(\n",
       "        (gate_proj): Linear(in_features=12, out_features=12, bias=True)\n",
       "        (up_proj): Linear(in_features=12, out_features=12, bias=True)\n",
       "        (down_proj): Linear(in_features=12, out_features=12, bias=True)\n",
       "        (gelu): GELU()\n",
       "      )\n",
       "      (norm2): UstaLayerNorm()\n",
       "    )\n",
       "    (6): UstaDecoderBlock(\n",
       "      (self_attention): UstaMultiHeadAttention(\n",
       "        (multi_head_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (projection): Linear(in_features=12, out_features=12, bias=True)\n",
       "      )\n",
       "      (norm1): UstaLayerNorm()\n",
       "      (mlp): UstaMLP(\n",
       "        (gate_proj): Linear(in_features=12, out_features=12, bias=True)\n",
       "        (up_proj): Linear(in_features=12, out_features=12, bias=True)\n",
       "        (down_proj): Linear(in_features=12, out_features=12, bias=True)\n",
       "        (gelu): GELU()\n",
       "      )\n",
       "      (norm2): UstaLayerNorm()\n",
       "    )\n",
       "    (7): UstaDecoderBlock(\n",
       "      (self_attention): UstaMultiHeadAttention(\n",
       "        (multi_head_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (projection): Linear(in_features=12, out_features=12, bias=True)\n",
       "      )\n",
       "      (norm1): UstaLayerNorm()\n",
       "      (mlp): UstaMLP(\n",
       "        (gate_proj): Linear(in_features=12, out_features=12, bias=True)\n",
       "        (up_proj): Linear(in_features=12, out_features=12, bias=True)\n",
       "        (down_proj): Linear(in_features=12, out_features=12, bias=True)\n",
       "        (gelu): GELU()\n",
       "      )\n",
       "      (norm2): UstaLayerNorm()\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=12, out_features=64, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = UstaModel(64, embedding_dim=12, num_heads=4, context_length=32, num_layers=8)\n",
    "loaded_model.load_state_dict(torch.load(\"u_model.pth\"))\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0806, grad_fn=<MaxBackward0>),\n",
       " tensor(1),\n",
       " tensor([4.0008e-02, 8.0611e-02, 2.3938e-02, 6.5549e-02, 5.6474e-02, 2.2162e-02,\n",
       "         1.1188e-02, 1.3218e-02, 7.0459e-03, 1.1149e-02, 1.2244e-02, 8.4896e-03,\n",
       "         7.5855e-03, 2.9734e-03, 2.7699e-02, 1.1703e-02, 6.0635e-03, 1.2244e-02,\n",
       "         4.2808e-03, 2.0172e-02, 2.4537e-02, 1.9631e-03, 1.3078e-03, 4.0889e-03,\n",
       "         8.5991e-03, 6.3138e-04, 8.7168e-04, 1.4288e-03, 7.3837e-04, 1.0692e-02,\n",
       "         2.0040e-02, 7.3611e-03, 2.9592e-02, 2.7569e-02, 1.2117e-02, 1.0960e-02,\n",
       "         1.9325e-02, 2.5441e-02, 3.0920e-03, 1.8819e-02, 3.0991e-02, 3.2736e-02,\n",
       "         2.8863e-02, 3.8441e-02, 3.3923e-02, 1.5534e-02, 6.8959e-03, 1.0716e-02,\n",
       "         1.3399e-02, 1.3336e-02, 1.5073e-03, 1.0691e-02, 4.0535e-02, 3.5729e-02,\n",
       "         9.3522e-04, 1.3994e-03, 1.9807e-03, 1.3315e-03, 2.9100e-03, 4.9543e-04,\n",
       "         2.4036e-03, 1.2725e-03, 2.6429e-07, 4.5393e-07],\n",
       "        grad_fn=<SoftmaxBackward0>))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = u_model(torch.tensor(new_tokens))\n",
    "\n",
    "probs = torch.softmax(out[-1], dim=-1)\n",
    "max_prob, max_index = torch.max(probs, dim=-1)\n",
    "max_prob, max_index, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16, 61, 5, 61, 14, 61, 1, 60]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "new_tokens = u_tokenizer.encode(\"madrid is in\")\n",
    "new_tokens = new_tokens.detach().cpu().numpy().tolist()\n",
    "new_tokens.append(61)\n",
    "\n",
    "u_model.generate(torch.tensor(new_tokens), 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
